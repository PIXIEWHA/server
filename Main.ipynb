{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uUVHIbOkr8AO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_buJpTAHQB7"},"outputs":[],"source":["!pip install import_ipynb\n","!pip install pyrebase\n","!pip install firebase_admin\n","!sudo apt-get install -y gpac\n","\n","%cd /content/drive/MyDrive/Notebooks/Yolov5_DeepSort_Pytorch\n","!pip install -r requirements.txt\n","\n","%cd /content/drive/MyDrive/Notebooks/\n","!pip install --upgrade pip\n","!pip install opencv-python\n","!pip install opencv-contrib-python\n","!pip install --upgrade opencv-python\n","!pip install google-api-python-client==1.7.3 oauth2client==4.1.2 progressbar2==3.38.0 httplib2==0.15.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"woKcARDIGcf3"},"outputs":[],"source":["# 라이브러리 설치 완료 시까지 기다림(에러 나지 않을 때까지 5번 정도 실행)\n","\n","import os\n","import cv2\n","import math\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","\n","import pyrebase\n","import firebase_admin\n","from firebase_admin import messaging\n","from firebase_admin import credentials\n","\n","import sys\n","sys.path.insert(0, \"/content/drive/MyDrive/Notebooks/Yolov5_DeepSort_Pytorch\")\n","sys.path.insert(0, '/content/drive/MyDrive/Notebooks/Yolov5_DeepSort_Pytorch/yolov5')\n","\n","from yolov5.utils.google_utils import attempt_download\n","from yolov5.models.experimental import attempt_load\n","from yolov5.utils.datasets import LoadImages, LoadStreams\n","from yolov5.utils.general import check_img_size, non_max_suppression, scale_coords, check_imshow, xyxy2xywh\n","from yolov5.utils.torch_utils import select_device, time_synchronized\n","from yolov5.utils.plots import plot_one_box\n","from deep_sort_pytorch.utils.parser import get_config\n","from deep_sort_pytorch.deep_sort import DeepSort\n","import argparse\n","import platform\n","import shutil\n","import time\n","from pathlib import Path\n","import torch\n","import torch.backends.cudnn as cudnn\n","\n","# 경로 지정\n","path = \"/content/drive/MyDrive/Notebooks/\"\n","yolo_cnt = 0\n","openpose_cnt = 0\n","yolo_result = False\n","openpose_result = False\n","\n","# OpenPose 변수\n","BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n","               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n","               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n","               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n","\n","POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n","               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n","               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n","               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n","               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n","\n","width = 368\n","height = 368\n","inWidth = width\n","inHeight = height\n","\n","%cd /content/drive/MyDrive/Notebooks/human-pose-estimation-opencv\n","net = cv2.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n","thr = 0.2\n","%cd /content/drive/MyDrive/Notebooks/\n","\n","# Yolo+DeepSort\n","def compute_color_for_id(label):\n","    \"\"\"\n","    Simple function that adds fixed color depending on the id\n","    \"\"\"\n","    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n","\n","    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n","    return tuple(color)\n","\n","\n","def detect(out, source, yolo_weights, deep_sort_weights, show_vid, save_vid, save_txt, imgsz, evaluate, config_deepsort, device, augment, conf_thres, iou_thres, classes, agnostic):\n","    global yolo_cnt\n","\n","    global trash\n","    global checkLong\n","\n","    webcam = source == '0' or source.startswith(\n","        'rtsp') or source.startswith('http') or source.endswith('.txt')\n","\n","    # initialize deepsort\n","    cfg = get_config()\n","    cfg.merge_from_file(config_deepsort)\n","    attempt_download(deep_sort_weights, repo='mikel-brostrom/Yolov5_DeepSort_Pytorch')\n","    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n","                        max_dist=cfg.DEEPSORT.MAX_DIST, min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n","                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP, max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n","                        max_age=cfg.DEEPSORT.MAX_AGE, n_init=cfg.DEEPSORT.N_INIT, nn_budget=cfg.DEEPSORT.NN_BUDGET,\n","                        use_cuda=True)\n","\n","    # Initialize\n","    device = select_device(device)\n","\n","    # The MOT16 evaluation runs multiple inference streams in parallel, each one writing to\n","    # its own .txt file. Hence, in that case, the output folder is not restored\n","    if not evaluate:\n","        if os.path.exists(out):\n","            pass\n","            shutil.rmtree(out)  # delete output folder\n","        os.makedirs(out)  # make new output folder\n","    half = device.type != 'cpu'  # half precision only supported on CUDA\n","\n","    # Load model\n","    model = attempt_load(yolo_weights, map_location=device)  # load FP32 model\n","    stride = int(model.stride.max())  # model stride\n","    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n","    names = model.module.names if hasattr(model, 'module') else model.names  # get class names\n","    if half:\n","        model.half()  # to FP16\n","\n","    # Set Dataloader\n","    vid_path, vid_writer = None, None\n","    # Check if environment supports image displays\n","    if show_vid:\n","        show_vid = check_imshow()\n","\n","    if webcam:\n","        cudnn.benchmark = True  # set True to speed up constant image size inference\n","        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz)\n","\n","    # Get names and colors\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","\n","    # Run inference\n","    if device.type != 'cpu':\n","        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n","    t0 = time.time()\n","\n","    save_path = str(Path(out))\n","    # extract what is in between the last '/' and last '.'\n","    txt_file_name = source.split('/')[-1].split('.')[0]\n","    txt_path = str(Path(out)) + '/' + txt_file_name + '.txt'\n","\n","    # 추가\n","    before = []\n","    total = []\n","    fr = []\n","    \n","    for frame_idx, (path, img, im0s, vid_cap) in enumerate(dataset):\n","        img = torch.from_numpy(img).to(device)\n","        img = img.half() if half else img.float()  # uint8 to fp16/32\n","        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","        if img.ndimension() == 3:\n","            img = img.unsqueeze(0)\n","\n","        # Inference\n","        t1 = time_synchronized()\n","        pred = model(img, augment=augment)[0]\n","\n","        # Apply NMS\n","        pred = non_max_suppression(\n","            pred, conf_thres, iou_thres, classes=classes, agnostic=agnostic)\n","        t2 = time_synchronized()\n","\n","        # Process detections\n","        for i, det in enumerate(pred):  # detections per image\n","            objects = []\n","            persons = []\n","            now = []\n","            \n","            if webcam:  # batch_size >= 1\n","                p, s, im0 = path[i], '%g: ' % i, im0s[i].copy()\n","            else:\n","                p, s, im0 = path, '', im0s\n","\n","            s += '%gx%g ' % img.shape[2:]  # print string\n","            save_path = str(Path(out) / Path(p).name)\n","\n","            if det is not None and len(det):\n","                # Rescale boxes from img_size to im0 size\n","                det[:, :4] = scale_coords(\n","                    img.shape[2:], det[:, :4], im0.shape).round()\n","\n","                # Print results\n","                for c in det[:, -1].unique():\n","                    n = (det[:, -1] == c).sum()  # detections per class\n","                    s += '%g %ss, ' % (n, names[int(c)])  # add to string\n","\n","                xywhs = xyxy2xywh(det[:, 0:4])\n","                confs = det[:, 4]\n","                clss = det[:, 5]\n","\n","                # pass detections to deepsort\n","                outputs = deepsort.update(xywhs.cpu(), confs.cpu(), clss, im0)\n","                \n","                # draw boxes for visualization\n","                if len(outputs) > 0:\n","                    for j, (output, conf) in enumerate(zip(outputs, confs)): \n","                        bboxes = output[0:4]\n","                        id = output[4]\n","                        cls = output[5]\n","\n","                        c = int(cls)  # integer class\n","                        label = f'{id} {names[c]} {conf:.2f}'\n","                        color = compute_color_for_id(id)\n","                        plot_one_box(bboxes, im0, label=label, color=color, line_thickness=2)\n","                        \n","                        # 모든 id와 좌표 저장\n","                        temp = [output[4], output[5], output[0], output[1], output[2]-output[0], output[3]-output[1]]\n","                        \n","                        if output[5]==0:\n","                            persons.append(temp)\n","                        else:\n","                            objects.append(temp)\n","                        \n","                        if save_txt:\n","                            # to MOT format\n","                            bbox_left = output[0]\n","                            bbox_top = output[1]\n","                            bbox_w = output[2] - output[0]\n","                            bbox_h = output[3] - output[1]\n","\n","                            # Write MOT compliant results to file\n","                            with open(txt_path, 'a') as f:\n","                               f.write(('%g ' * 10 + '\\n') % (frame_idx, id, bbox_left,\n","                                                           bbox_top, bbox_w, bbox_h, -1, -1, -1, -1))  # label format\n","\n","            else:\n","                deepsort.increment_ages()\n","\n","            print()\n","            print(\"person : \", persons)\n","            print(\"object : \", objects)             \n","\n","            # if (a.x + a.width) >= (b.x) and (a.y) <= (b.y + b.height)  and (a.y + a.height) >= (b.y): 확인 및 겹침 저장\n","            for p in persons:\n","                for o in objects:\n","                    if [p[0], o[0]] in now:\n","                        continue\n","\n","                    if (p[2] + p[4]) >= o[2] and (p[3] <= (o[3] + o[5]) or p[3] + p[5] >= o[3]):\n","                        now.append([p[0], o[0]])\n","                        fr.append([p[0], o[0], frame_idx])\n","\n","                    elif (o[2] + o[4]) >= p[2] and (o[3] <= (p[3] + p[5]) or o[3] + o[5] >= p[3]):\n","                        now.append([p[0], o[0]])\n","                        fr.append([p[0], o[0], frame_idx])\n","\n","            # person은 존재하나, object가 없어졌을 때 투기\n","            print(\"before: \", before)\n","            print(\"now: \", now)\n","            print(\"total: \", total)\n","\n","            if len(before) != 0:\n","              for b in before:\n","                if b not in now:\n","                  if b not in total:\n","                    yolo_cnt += 1\n","                    print(\"yolo_cnt: \", yolo_cnt)\n","\n","            for b in before:\n","              if b not in total:\n","                total.append(b)     \n","            \n","            for f in fr:\n","              if f[2] < (frame_idx - 20):\n","                for t in total:\n","                  if t[0] == f[0] and t[1] == f[1]:\n","                    total.remove(t)\n","\n","            before = now\n","\n","            # Print time (inference + NMS)\n","            print('Done. (%.3fs)' % (t2 - t1))\n","\n","            # Stream results\n","            if show_vid:\n","                cv2.imshow(p, im0)\n","                if cv2.waitKey(1) == ord('q'):  # q to quit\n","                    raise StopIteration\n","\n","            # Save results (image with detections)\n","            if save_vid:\n","                if vid_path != save_path:  # new video\n","                    vid_path = save_path\n","                    if isinstance(vid_writer, cv2.VideoWriter):\n","                        vid_writer.release()  # release previous video writer\n","                    if vid_cap:  # video\n","                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                    else:  # stream\n","                        fps, w, h = 6, im0.shape[1], im0.shape[0]\n","                        save_path += '.mp4'\n","\n","                    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","                vid_writer.write(im0)\n","\n","    if save_txt or save_vid:\n","        print('Results saved to %s' % os.getcwd() + os.sep + out)\n","        if platform == 'darwin':  # MacOS\n","            os.system('open ' + save_path)\n","\n","    print('Done. (%.3fs)' % (time.time() - t0))\n","\n","# Pose Estimation\n","def poseDetector(frame):\n","    global openpose_cnt\n","    \n","    # GPU 사용\n","    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n","    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n","\n","    frameWidth = frame.shape[1]\n","    frameHeight = frame.shape[0]\n","    \n","    net.setInput(cv2.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n","    out = net.forward()\n","    out = out[:, :19, :, :] \n","    # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n","\n","    assert(len(BODY_PARTS) == out.shape[1])\n","\n","    # 포인트 찾기\n","    points = []\n","    for i in range(len(BODY_PARTS)):\n","        heatMap = out[0, i, :, :]\n","\n","        _, conf, _, point = cv2.minMaxLoc(heatMap)\n","\n","        # 원본 이미지에 맞게 위치 수정\n","        x = (frameWidth * point[0]) / out.shape[3]\n","        y = (frameHeight * point[1]) / out.shape[2]\n","        points.append((int(x), int(y)) if conf > thr else None)\n","\n","    # 자세 확인(1-8, 4-10, 4-13, 7-10, 7-13)\n","    pt = [[1,8],[4,10],[4,13],[7,10],[7,13]]\n","    for p in pt:\n","      if (points[p[0]] is not None) and (points[p[1]] is not None):\n","        dx = points[p[0]][0] - points[p[1]][0]\n","        dy = points[p[0]][1] - points[p[1]][1]\n","        rad = math.atan2(abs(dy), abs(dx))\n","        deg = rad * 180 / math.pi\n","\n","        if deg < 45:\n","          openpose_cnt += 1\n","          #print(openpose_cnt)\n","\n","    # 표시\n","    for pair in POSE_PAIRS:\n","        partFrom = pair[0]\n","        partTo = pair[1]\n","        assert(partFrom in BODY_PARTS)\n","        assert(partTo in BODY_PARTS)\n","\n","        idFrom = BODY_PARTS[partFrom]\n","        idTo = BODY_PARTS[partTo]\n","\n","        if points[idFrom] and points[idTo]:\n","            cv2.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n","            cv2.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n","            cv2.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n","\n","    t, _ = net.getPerfProfile()\n","\n","    return frame\n","\n","def send_to_firebase_cloud_messaging():\n","    topic = 'pixie'\n","\n","    message = messaging.Message(\n","        notification=messaging.Notification(\n","        title=\"쓰레기 무단 투기 알림\",\n","        body=\"쓰레기 무단 투기가 의심되는 영상을 발견했습니다. PIXIE 어플에서 확인해주세요.\",\n","        ),\n","        topic=topic,\n","    )\n","\n","    response = messaging.send(message)\n","\n","    print('알림 성공적으로 전송 완료:', response)\n","\n","# 투기 인식\n","def trashDumping(filename, id):\n","  global yolo_cnt\n","  global yolo_result\n","  global openpose_cnt\n","  global openpose_result\n","  yolo_cnt = 0\n","  openpose_cnt = 0\n","  yolo_result = False\n","  openpose_result = False \n","\n","  # Yolo+DeepSort 실행\n","  if os.path.isfile(path+id+\"temp/\"+filename+\".mp4\") == False:\n","    os.chdir(path+\"Yolov5_DeepSort_Pytorch\")\n","    print(path+id+\"temp/\"+filename+\".mp4 영상 Yolo+DeepSort 실행 중\")\n","    print(\"Output: \"+path+id+\"temp/\"+filename+\".mp4\")\n","    detect(agnostic=False, augment=False, classes=None, conf_thres=0.2, \\\n","           config_deepsort='/content/drive/MyDrive/Notebooks/Yolov5_DeepSort_Pytorch/deep_sort_pytorch/configs/deep_sort.yaml', \\\n","           deep_sort_weights='/content/drive/MyDrive/Notebooks/Yolov5_DeepSort_Pytorch/deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7', device='', evaluate=False, \\\n","           imgsz=640, iou_thres=0.2, out=path+id+\"/temp/\"+filename, save_txt=False, save_vid=True, show_vid=False, \\\n","           source=path+id+\"/video/\"+filename+\".mp4\", yolo_weights='/content/drive/MyDrive/Notebooks/best.pt')\n","    #!python3 track.py --source {path}{id}video/{filename}.mp4 --yolo_weights {path}563.pt --output {path}{id}temp/{filename} --save-vid\n","    print(\"Yolo+DeepSort 완료\")\n","    os.chdir(path)\n","\n","  # OpenPose 실행\n","  if os.path.isfile(path+id+\"output/\"+filename+\".mp4\") == False:\n","    cap = cv2.VideoCapture(path+id+\"temp/\"+filename+\"/\"+filename+\".mp4\")\n","    print(\"파일 이름: \"+path+id+\"temp/\"+filename+\"/\"+filename+\".mp4\")\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","      print(\"해당 파일을 찾지 못했습니다.\")\n","\n","    frame_height, frame_width, _ = frame.shape\n","    out = cv2.VideoWriter(path+id+\"output/\"+filename+\".mp4\",cv2.VideoWriter_fourcc('M','J','P','G'), 25, (frame_width,frame_height))\n","    print(\"OpenPose 실행 중\")\n","    print(path+id+\"output/\"+filename+\".mp4 결과 저장\")\n","\n","    while cap.isOpened():\n","      ret, frame = cap.read()\n","\n","      if not ret:\n","        out.release()\n","        break\n","\n","      now_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n","      total_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","      print(f\"=== frame: {now_frame:.0f} / {total_frame:.0f} ===\")\n","\n","      output = poseDetector(frame)\n","      out.write(output)\n","    out.release()\n","    print(\"OpenPose 확인 완료\")\n","\n","  if yolo_cnt > 1:\n","    yolo_result = True\n","\n","  if openpose_cnt > 5:\n","    openpose_result = True\n","\n","  print(filename)\n","  # print(\"Yolo+DeepSORT 인식 결과:\", yolo_cnt, \" => \", yolo_result)\n","  # print(\"OpenPose 인식 결과:\", openpose_cnt, \" => \", openpose_result)\n","  \n","  # 무단 투기 의심\n","  if yolo_result == True and openpose_result == True:\n","    # Upload\n","    #storage.child(id+\"output/\"+filename+\"_result.mp4\").put(path+id+\"output/\"+filename+\".mp4\")\n","    print(filename, \"영상 DB Upload 완료\")\n","    send_to_firebase_cloud_messaging()\n","     \n","  # Delete\n","  #storage.delete(id+filename+\".h264\")\n","  \n","  #os.remove(path+id+filename+\".h264\")\n","  #os.remove(path+id+filename+\".mp4\")\n","  #os.remove(path+\"temp/\"+id+filename+\".mp4\")\n","\n"," # print(\"Delete 완료\")\n"," # print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQKXV-LRhKN9"},"outputs":[],"source":["if __name__ == \"__main__\":\n","  cred = credentials.Certificate(path+\"pixie-b4bf8-firebase-adminsdk-cdjsi-09a89665de.json\") # json\n","  firebase_admin.initialize_app(cred)\n","\n","  config={\n","\t\"apiKey\": \"AIzaSyAn13FTdnfEaWl_KRpU3H1HEwr3NOz9vIE\", #webkey\n","\t\"authDomain\": \"pixie-b4bf8.firebaseapp.com\", #ID\n","\t\"databaseURL\": \"https://pixie-b4bf8-default-rtdb.asia-southeast1.firebasedatabase.app\", #database url\n","\t\"storageBucket\": \"pixie-b4bf8.appspot.com\", #storage\n","\t\"serviceAccount\": path+\"pixie-b4bf8-firebase-adminsdk-cdjsi-09a89665de.json\" # json\n","  }\n","\n","  firebase = pyrebase.initialize_app(config)\n","  storage = firebase.storage()\n","\n","  #while(True):\n","  files = storage.list_files()\n","  makeSet = []\n","\n","  # 라즈베리파이 영상 다운로드 후 .h264 -> .mp4 파일 형식 바꿈\n","  # for file in files:\n","  #   temp = file.name.split(\"/\")\n","  #   ip = temp[0]\n","  #   os.chdir(path)\n","\n","  #   # create video folder\n","  #   if os.path.isdir(ip)==False:\n","  #     os.mkdir(ip)\n","  #     os.chdir(\"./\"+ip)\n","  #     os.mkdir(\"output\")\n","  #     os.mkdir(\"video\")\n","  #     os.mkdir(\"../temp/\"+ip)\n","  #   else:\n","  #     os.chdir(\"./\"+ip)\n","    \n","  #   if (file.name[-5:]==\".h264\"):\n","  #     filename = temp[len(temp)-1]\n","  #     filename = filename[:-5]\n","       \n","  #     li = os.listdir(path+ip)\n","        \n","  #     # firebase storage download\n","  #     if filename+\".mp4\" not in li:\n","  #       if filename+\".h264\" not in li:\n","  #         print(path+ip+\"/video/\"+filename+\".h264\")\n","  #         print(filename+\" downloading\")\n","  #         file.download_to_filename(filename+\".h264\")\n","\n","  #       # .h264 -> .mp4  \n","  #       print(filename+\" converting mp4\")\n","  #       os.system(\"MP4Box -add\"+\" ./video/\"+filename+\".h264\"+\" ./video/\"+filename+\".mp4\") \n","    \n","  #     trashDumping(filename, ip+\"/\")\n","\n","# 테스트 영상 예시\n","# 결과 https://drive.google.com/drive/folders/158kncW3GgnnqDDs0-zNTlrE3TjGXQsH1\n","for i in os.listdir(\"/content/drive/MyDrive/Notebooks/192.168.137.76/video\"):\n","  if i == \"putdown8_multiple_run_Trim.mp4\":\n","    trashDumping(i[:-4], \"192.168.137.76/\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Main.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
